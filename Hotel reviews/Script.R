required_packages <- c("magrittr", "tm", "mlr", "e1071", "dplyr", "kernlab", "lubridate", "dtplyr",
                       "readr", "ggplot2", "tidytext", "stringr", "tidyr", "scales", "broom",
                       "SnowballC", "wordcloud", "reshape2", "RTextTools", "rvest",
                       "tibble", "devtools", "DBI", "httr", "RSQLite", "RMySQL")

x <- lapply(required_packages, library, character.only = TRUE)
install_github("ronald245/RTextTools", subdir = "RTextTools")

extra_scripts <- c("Tools.R", "Sentiment.R", "Classifiers.R", "CleanData.R", "Scraper.R")
x <- lapply(extra_scripts, source)

database <- "HotelReviews"

if (!file.exists(database)) {
    CleanCSV("Hotel_Reviews.csv")
    
    con <- dbConnect(RMySQL::MySQL(), user = 'username', password = "password", dbname = database)
    df <- as_tibble(dbReadTable(con, "Original"))
    dbDisconnect(con)

    getContribution(df, get_sentiments("afinn"))

    # randomise 
    df <- df[sample(nrow(df)),]
    df <- df[sample(nrow(df)),]
    df <- df[1: as.integer(nrow(df) / 1000),]
    df <- df[complete.cases(df),]
    
    SaveMatrix(df)
}

load("originalMatrix.Rd")


if (!file.exists("trainedModels.Rd")) {
    TrainClassifiers(df, doc_matrix)
}

#load the models we defined earlier
load("trainedModels.Rd")

con <- dbConnect(RSQLite::SQLite(), dbname = database)
scraped.exists <- dbExistsTable(con, "Scraped")
dbDisconnect(con)

if (!scraped.exists) {
    ScrapeHotels()
    ScrapeTripExpert()
}


numScrapedReviews <- ExecuteSQL(database, "select count(*) from scraped")
con <- dbConnect(RMySQL::MySQL(), user = 'username', password = "password", dbname = database)
newData <- as_tibble(dbReadTable(con, "scraped"))

dbDisconnect(con)

newData <- newData[complete.cases(newData),]


test <- tibble(review_body = paste(newData$review.summary, newData$review.text, " "), Consensus =   newData$ )
test$review_body = CleanBody(test$review_body)

new_matrix <- create_matrix(test[, "review_body"],
                            language = "english",
                            removeNumbers = TRUE,
                            stemWords = TRUE,
                            removeSparseTerms = .99,
                            weighting = weightTfIdf,
                            originalMatrix = doc_matrix)

container <- create_container(new_matrix,
                              test$Consensus,
                              testSize = 1:nrow(test),
                              virgin = TRUE)

results <- classify_models(container, models)

test$MAXENTROPY_LABEL = results$MAXENTROPY_LABEL
test$SVM_LABEL = results$SVM_LABEL
test$FORESTS_LABEL = results$FORESTS_LABEL

for (i in c(1:nrow(test))) {
    consensus = 0
    consensus <- if (results$MAXENTROPY_LABEL[i] == +1) consensus + 1 else consensus - 1
    consensus <- if (results$SVM_LABEL[i] == +1) consensus + 1 else consensus - 1
    consensus <- if (results$FORESTS_LABEL[i] == +1)  consensus + 1 else consensus - 1
   
    test$Consensus[i] = consensus
}


analytics <- create_analytics(container, results)
